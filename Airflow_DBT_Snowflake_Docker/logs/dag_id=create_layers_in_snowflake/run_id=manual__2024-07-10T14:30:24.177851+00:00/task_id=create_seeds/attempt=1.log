[2024-07-10 14:30:24,911] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: create_layers_in_snowflake.create_seeds manual__2024-07-10T14:30:24.177851+00:00 [queued]>
[2024-07-10 14:30:24,921] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: create_layers_in_snowflake.create_seeds manual__2024-07-10T14:30:24.177851+00:00 [queued]>
[2024-07-10 14:30:24,922] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2024-07-10 14:30:24,922] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2024-07-10 14:30:24,922] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2024-07-10 14:30:24,937] {taskinstance.py:1377} INFO - Executing <Task(DockerOperator): create_seeds> on 2024-07-10 14:30:24.177851+00:00
[2024-07-10 14:30:24,940] {standard_task_runner.py:52} INFO - Started process 2404 to run task
[2024-07-10 14:30:24,944] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'create_layers_in_snowflake', 'create_seeds', 'manual__2024-07-10T14:30:24.177851+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/create_layers.py', '--cfg-path', '/tmp/tmp792i99py', '--error-file', '/tmp/tmpj3dotlua']
[2024-07-10 14:30:24,944] {standard_task_runner.py:80} INFO - Job 22: Subtask create_seeds
[2024-07-10 14:30:25,005] {task_command.py:369} INFO - Running <TaskInstance: create_layers_in_snowflake.create_seeds manual__2024-07-10T14:30:24.177851+00:00 [running]> on host bc9f9d1e47b7
[2024-07-10 14:30:25,080] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=create_layers_in_snowflake
AIRFLOW_CTX_TASK_ID=create_seeds
AIRFLOW_CTX_EXECUTION_DATE=2024-07-10T14:30:24.177851+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-07-10T14:30:24.177851+00:00
[2024-07-10 14:30:25,101] {docker.py:247} INFO - Starting docker container from image custom_dbt_image
[2024-07-10 14:30:25,203] {docker.py:308} INFO - chmod: cannot access '/dbtlearn': No such file or directory
[2024-07-10 14:30:25,250] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 387, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 266, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 313, in _run_image_with_mounts
    raise AirflowException(f'Docker container failed: {repr(result)} lines {joined_log_lines}')
airflow.exceptions.AirflowException: Docker container failed: {'StatusCode': 1} lines chmod: cannot access '/dbtlearn': No such file or directory
[2024-07-10 14:30:25,254] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=create_layers_in_snowflake, task_id=create_seeds, execution_date=20240710T143024, start_date=20240710T143024, end_date=20240710T143025
[2024-07-10 14:30:25,265] {standard_task_runner.py:97} ERROR - Failed to execute job 22 for task create_seeds (Docker container failed: {'StatusCode': 1} lines chmod: cannot access '/dbtlearn': No such file or directory; 2404)
[2024-07-10 14:30:25,291] {local_task_job.py:156} INFO - Task exited with return code 1
[2024-07-10 14:30:25,343] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
